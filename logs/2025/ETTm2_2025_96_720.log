Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, checkpoints='./checkpoints/', d_model=256, d_twff=256, d_vwff=128, data='ETTm2', data_path='ETTm2.csv', des='Exp', devices='0,1,2,3', do_predict=False, dropout=0.1, e_layers=1, embed='timeF', enc_in=7, features='M', flatten_mod=1, freq='h', gpu=0, head_dropout=0.1, init_residual_weight_list=[1.5, 1.0, 1.0], inverse=False, is_training=1, itr=1, label_len=0, learning_rate=0.0005, loss='MSE', lradj='type1', mask=0, mod=0, model='L3former', model_id='ETTm2_96_720', n_heads=8, num_workers=10, output_attention=False, patience=10, pct_start=0.2, pred_len=720, random_seed=2025, revin=1, root_path='./dataset/ETT-small/', seq_len=96, target='OT', train_epochs=10, train_residual_weight=1, use_L3Linear=0, use_amp=False, use_gpu=True, use_multi_gpu=False, use_norm_in_former=1, use_pooling_init=0, use_scheduler=0, use_std_in_revin=1, use_vwff=1, vwff_dropout=0.8, window_size_list=[3, 7, 15, 27])
Use GPU: cuda:0
>>>>>>>start training : ETTm2_96_720_L3former_ETTm2_M_ft96_sl0_ll720_pl256_dm8_nh1_el256_dftimeF_ebExp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4856699
	speed: 0.0167s/iter; left time: 42.1446s
	iters: 200, epoch: 1 | loss: 0.3456067
	speed: 0.0127s/iter; left time: 30.9802s
Epoch: 1 cost time: 3.7805891036987305
Epoch: 1, Steps: 263 | Train Loss: 0.6023694 Vali Loss: 0.2882458 Test Loss: 0.4037221
Validation loss decreased (inf --> 0.288246).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.4849466
	speed: 0.0429s/iter; left time: 97.2561s
	iters: 200, epoch: 2 | loss: 0.4442272
	speed: 0.0116s/iter; left time: 25.0617s
Epoch: 2 cost time: 3.2817094326019287
Epoch: 2, Steps: 263 | Train Loss: 0.5747206 Vali Loss: 0.2926157 Test Loss: 0.3992089
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6308548
	speed: 0.0439s/iter; left time: 87.9829s
	iters: 200, epoch: 3 | loss: 0.5851088
	speed: 0.0131s/iter; left time: 24.9853s
Epoch: 3 cost time: 3.6359829902648926
Epoch: 3, Steps: 263 | Train Loss: 0.5623944 Vali Loss: 0.2880274 Test Loss: 0.3954351
Validation loss decreased (0.288246 --> 0.288027).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.5888719
	speed: 0.0455s/iter; left time: 79.1860s
	iters: 200, epoch: 4 | loss: 0.6245453
	speed: 0.0125s/iter; left time: 20.5020s
Epoch: 4 cost time: 3.636185884475708
Epoch: 4, Steps: 263 | Train Loss: 0.5519496 Vali Loss: 0.2912017 Test Loss: 0.3958104
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.5786357
	speed: 0.0440s/iter; left time: 65.0527s
	iters: 200, epoch: 5 | loss: 0.3588083
	speed: 0.0124s/iter; left time: 17.0967s
Epoch: 5 cost time: 3.568652391433716
Epoch: 5, Steps: 263 | Train Loss: 0.5463025 Vali Loss: 0.2929279 Test Loss: 0.3965401
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.5888780
	speed: 0.0451s/iter; left time: 54.8987s
	iters: 200, epoch: 6 | loss: 0.6525306
	speed: 0.0133s/iter; left time: 14.8226s
Epoch: 6 cost time: 3.645451784133911
Epoch: 6, Steps: 263 | Train Loss: 0.5420800 Vali Loss: 0.2920832 Test Loss: 0.3966653
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6825735
	speed: 0.0435s/iter; left time: 41.4160s
	iters: 200, epoch: 7 | loss: 0.6042245
	speed: 0.0126s/iter; left time: 10.7158s
Epoch: 7 cost time: 3.4216277599334717
Epoch: 7, Steps: 263 | Train Loss: 0.5405475 Vali Loss: 0.2928898 Test Loss: 0.3976119
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6759347
	speed: 0.0459s/iter; left time: 31.6694s
	iters: 200, epoch: 8 | loss: 0.5307597
	speed: 0.0135s/iter; left time: 7.9369s
Epoch: 8 cost time: 3.892057180404663
Epoch: 8, Steps: 263 | Train Loss: 0.5395094 Vali Loss: 0.2929495 Test Loss: 0.3977485
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.5589107
	speed: 0.0451s/iter; left time: 19.2703s
	iters: 200, epoch: 9 | loss: 0.5935990
	speed: 0.0127s/iter; left time: 4.1593s
Epoch: 9 cost time: 3.5817573070526123
Epoch: 9, Steps: 263 | Train Loss: 0.5387250 Vali Loss: 0.2930766 Test Loss: 0.3977182
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6050566
	speed: 0.0441s/iter; left time: 7.2381s
	iters: 200, epoch: 10 | loss: 0.5383048
	speed: 0.0128s/iter; left time: 0.8210s
Epoch: 10 cost time: 3.594087600708008
Epoch: 10, Steps: 263 | Train Loss: 0.5382958 Vali Loss: 0.2930558 Test Loss: 0.3978067
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
>>>>>>>testing : ETTm2_96_720_L3former_ETTm2_M_ft96_sl0_ll720_pl256_dm8_nh1_el256_dftimeF_ebExp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (10801, 720, 7) (10801, 720, 7)
test shape: (10801, 720, 7) (10801, 720, 7)
mse:0.39288121461868286, mae:0.39362862706184387
