Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, checkpoints='./checkpoints/', d_model=128, d_twff=128, d_vwff=40, data='ETTh2', data_path='ETTh2.csv', des='Exp', devices='0,1,2,3', do_predict=False, dropout=0.1, e_layers=1, embed='timeF', enc_in=7, features='M', flatten_mod=0, freq='h', gpu=0, head_dropout=0.1, init_residual_weight_list=[1.0, 1.0, 1.0], inverse=False, is_training=1, itr=1, label_len=0, learning_rate=0.001, loss='MSE', lradj='type1', mask=0, mod=0, model='L3former', model_id='ETTh2_96_96', n_heads=8, num_workers=10, output_attention=False, patience=10, pct_start=0.2, pred_len=720, random_seed=2025, revin=1, root_path='./dataset/ETT-small/', seq_len=96, target='OT', train_epochs=10, train_residual_weight=1, use_L3Linear=0, use_amp=False, use_gpu=True, use_multi_gpu=False, use_norm_in_former=1, use_pooling_init=1, use_scheduler=0, use_std_in_revin=1, use_vwff=1, vwff_dropout=0.5, window_size_list=[3, 7, 15, 27])
Use GPU: cuda:0
>>>>>>>start training : ETTh2_96_96_L3former_ETTh2_M_ft96_sl0_ll720_pl128_dm8_nh1_el128_dftimeF_ebExp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7825
val 2161
test 2161
Epoch: 1 cost time: 1.2135977745056152
Epoch: 1, Steps: 61 | Train Loss: 0.8683239 Vali Loss: 0.6074488 Test Loss: 0.4254820
Validation loss decreased (inf --> 0.607449).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9125683307647705
Epoch: 2, Steps: 61 | Train Loss: 0.8151865 Vali Loss: 0.6302735 Test Loss: 0.4176530
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9943456649780273
Epoch: 3, Steps: 61 | Train Loss: 0.7752064 Vali Loss: 0.6199440 Test Loss: 0.4109488
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.0686187744140625
Epoch: 4, Steps: 61 | Train Loss: 0.7556880 Vali Loss: 0.6072451 Test Loss: 0.4082625
Validation loss decreased (0.607449 --> 0.607245).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.0851521492004395
Epoch: 5, Steps: 61 | Train Loss: 0.7468259 Vali Loss: 0.6058575 Test Loss: 0.4085621
Validation loss decreased (0.607245 --> 0.605857).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9893498420715332
Epoch: 6, Steps: 61 | Train Loss: 0.7428313 Vali Loss: 0.6033326 Test Loss: 0.4067584
Validation loss decreased (0.605857 --> 0.603333).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.0329599380493164
Epoch: 7, Steps: 61 | Train Loss: 0.7398326 Vali Loss: 0.6046292 Test Loss: 0.4070314
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.0765163898468018
Epoch: 8, Steps: 61 | Train Loss: 0.7401973 Vali Loss: 0.6016660 Test Loss: 0.4070043
Validation loss decreased (0.603333 --> 0.601666).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.005082607269287
Epoch: 9, Steps: 61 | Train Loss: 0.7392417 Vali Loss: 0.6044128 Test Loss: 0.4070140
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9066593647003174
Epoch: 10, Steps: 61 | Train Loss: 0.7376083 Vali Loss: 0.6035939 Test Loss: 0.4069820
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
>>>>>>>testing : ETTh2_96_96_L3former_ETTh2_M_ft96_sl0_ll720_pl128_dm8_nh1_el128_dftimeF_ebExp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.40558314323425293, mae:0.43406715989112854
